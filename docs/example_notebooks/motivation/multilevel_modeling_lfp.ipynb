{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multilevel modeling of LFP\n",
    "This is a slight reworking of the radon example from pymc3 https://docs.pymc.io/notebooks/multilevel_modeling.html\n",
    "\n",
    "Why this notebook? It's a common departure point to consider multilevel models in neuroscience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hierarchical or multilevel modeling is a generalization of regression modeling. *Multilevel models* are regression models in which the constituent model parameters are given **probability models**. This implies that model parameters are allowed to **vary by group**. Observational units are often naturally **clustered**. Clustering induces dependence between observations, despite random sampling of clusters and random sampling within clusters.\n",
    "\n",
    "A *hierarchical model* is a particular multilevel model where parameters are nested within one another. Some multilevel structures are not hierarchical -- e.g. \"country\" and \"year\" are not nested, but may represent separate, but overlapping, clusters of parameters. We will motivate this topic using a neuroscience example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Example: LFP power (modified Gelman and Hill 2006)\n",
    "\n",
    "LFP power is a measure of neuronal activity. It can varies greatly from mouse to mouse.\n",
    "\n",
    "The EPA did a study of radon levels in 80,000 households (more on this study and modeling here https://pymc3-testing.readthedocs.io/en/rtd-docs/notebooks/multilevel_modeling.html). We are going to call homes \"trials\", counties \"mice\", and radon levels \"power.\" The power is going to vary depending on \"no_stim\" (originally floor condition) or \"stim\" (originally basement condition) that in our case denote, say, optogenetic stimulation. There are two important predictors:\n",
    "\n",
    "* measurement in stim or first no_stim (power higher in stims)\n",
    "* mouse power level (positive correlation with power levels by mouse)\n",
    "\n",
    "The hierarchy in this example is neurons within mouse. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "First, we import the data from a local file, and extract data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import warnings\n",
    "from theano import tensor as tt\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "RANDOM_SEED = 8924\n",
    "np.random.seed(286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "# Import power data\n",
    "srrs2 = pd.read_csv(pm.get_data('srrs2.dat'))\n",
    "srrs2.columns = srrs2.columns.map(str.strip)\n",
    "# Select a subset of \"mice\" from Minnesota\n",
    "srrs_mn = srrs2[srrs2.state=='MN'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Next, obtain the mouse-level predictor, power, by combining two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "srrs_mn['fips'] = srrs_mn.stfips*1000 + srrs_mn.cntyfips\n",
    "cty = pd.read_csv(pm.get_data('cty.dat'))\n",
    "cty_mn = cty[cty.st=='MN'].copy()\n",
    "cty_mn[ 'fips'] = 1000*cty_mn.stfips + cty_mn.ctfips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['idnum', 'state', 'state2', 'stfips', 'zip', 'region', 'typebldg',\n",
      "       'floor', 'room', 'basement', 'windoor', 'rep', 'stratum', 'wave',\n",
      "       'starttm', 'stoptm', 'startdt', 'stopdt', 'activity', 'pcterr', 'adjwt',\n",
      "       'dupflag', 'zipflag', 'cntyfips', 'county', 'fips'],\n",
      "      dtype='object') (919, 26)\n",
      "Index(['stfips', 'ctfips', 'st', 'cty', 'lon', 'lat', 'Uppm', 'fips'], dtype='object') (89, 8)\n"
     ]
    }
   ],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "print(srrs_mn.columns,srrs_mn.shape)\n",
    "print(cty_mn.columns,cty_mn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Use the `merge` method to combine neuron- and mouse-level information in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "srrs_mn = srrs_mn.merge(cty_mn[['fips', 'Uppm']], on='fips')\n",
    "srrs_mn = srrs_mn.drop_duplicates(subset='idnum')\n",
    "u = np.log(srrs_mn.Uppm).unique()\n",
    "\n",
    "n = len(srrs_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idnum</th>\n",
       "      <th>state</th>\n",
       "      <th>state2</th>\n",
       "      <th>stfips</th>\n",
       "      <th>zip</th>\n",
       "      <th>region</th>\n",
       "      <th>typebldg</th>\n",
       "      <th>no_stim</th>\n",
       "      <th>room</th>\n",
       "      <th>stim</th>\n",
       "      <th>...</th>\n",
       "      <th>stopdt</th>\n",
       "      <th>power</th>\n",
       "      <th>pcterr</th>\n",
       "      <th>adjwt</th>\n",
       "      <th>dupflag</th>\n",
       "      <th>zipflag</th>\n",
       "      <th>cntyfips</th>\n",
       "      <th>mouse</th>\n",
       "      <th>fips</th>\n",
       "      <th>Uppm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5081</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55735</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>12288</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1146.499190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>27001</td>\n",
       "      <td>0.502054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5082</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55748</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>12088</td>\n",
       "      <td>2.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>471.366223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>27001</td>\n",
       "      <td>0.502054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5083</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55748</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>21188</td>\n",
       "      <td>2.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>433.316718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>27001</td>\n",
       "      <td>0.502054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5084</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>56469</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>123187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>461.623670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>27001</td>\n",
       "      <td>0.502054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5085</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55011</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>13088</td>\n",
       "      <td>3.1</td>\n",
       "      <td>13.8</td>\n",
       "      <td>433.316718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>ANOKA</td>\n",
       "      <td>27003</td>\n",
       "      <td>0.428565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   idnum state state2  stfips    zip  region  typebldg  no_stim  room stim  \\\n",
       "0   5081    MN     MN      27  55735       5         1        1     3    N   \n",
       "1   5082    MN     MN      27  55748       5         1        0     4    Y   \n",
       "2   5083    MN     MN      27  55748       5         1        0     4    Y   \n",
       "3   5084    MN     MN      27  56469       5         1        0     4    Y   \n",
       "4   5085    MN     MN      27  55011       3         1        0     4    Y   \n",
       "\n",
       "   ...  stopdt power  pcterr        adjwt  dupflag  zipflag  cntyfips  \\\n",
       "0  ...   12288   2.2     9.7  1146.499190        1        0         1   \n",
       "1  ...   12088   2.2    14.5   471.366223        0        0         1   \n",
       "2  ...   21188   2.9     9.6   433.316718        0        0         1   \n",
       "3  ...  123187   1.0    24.3   461.623670        0        0         1   \n",
       "4  ...   13088   3.1    13.8   433.316718        0        0         3   \n",
       "\n",
       "                  mouse   fips      Uppm  \n",
       "0  AITKIN                27001  0.502054  \n",
       "1  AITKIN                27001  0.502054  \n",
       "2  AITKIN                27001  0.502054  \n",
       "3  AITKIN                27001  0.502054  \n",
       "4  ANOKA                 27003  0.428565  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "srrs_mn['Uppm'].unique().shape,srrs_mn['activity'].unique().shape\n",
    "#plt.scatter(srrs_mn['Uppm'],srrs_mn['activity'])\n",
    "\n",
    "# HIDE CODE\n",
    "\n",
    "# Rename environmental variables to represent \n",
    "# what we think of as a neuroscience example\n",
    "srrs_mn.rename({'floor':'no_stim','basement':'stim','county':'mouse',\n",
    "                'activity':'power'},axis=1,inplace=True)\n",
    "\n",
    "# HIDE CODE\n",
    "\n",
    "srrs_mn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "# Rename environmental variables to represent \n",
    "# what we think of as a neuroscience example\n",
    "srrs_mn.rename({'floor':'no_stim','basement':'stim','county':'mouse',\n",
    "                'activity':'power'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idnum</th>\n",
       "      <th>state</th>\n",
       "      <th>state2</th>\n",
       "      <th>stfips</th>\n",
       "      <th>zip</th>\n",
       "      <th>region</th>\n",
       "      <th>typebldg</th>\n",
       "      <th>no_stim</th>\n",
       "      <th>room</th>\n",
       "      <th>stim</th>\n",
       "      <th>...</th>\n",
       "      <th>stopdt</th>\n",
       "      <th>power</th>\n",
       "      <th>pcterr</th>\n",
       "      <th>adjwt</th>\n",
       "      <th>dupflag</th>\n",
       "      <th>zipflag</th>\n",
       "      <th>cntyfips</th>\n",
       "      <th>mouse</th>\n",
       "      <th>fips</th>\n",
       "      <th>Uppm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5081</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55735</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>12288</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1146.499190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>27001</td>\n",
       "      <td>0.502054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5082</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55748</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>12088</td>\n",
       "      <td>2.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>471.366223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>27001</td>\n",
       "      <td>0.502054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5083</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55748</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>21188</td>\n",
       "      <td>2.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>433.316718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>27001</td>\n",
       "      <td>0.502054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5084</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>56469</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>123187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>461.623670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>27001</td>\n",
       "      <td>0.502054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5085</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55011</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>13088</td>\n",
       "      <td>3.1</td>\n",
       "      <td>13.8</td>\n",
       "      <td>433.316718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>ANOKA</td>\n",
       "      <td>27003</td>\n",
       "      <td>0.428565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   idnum state state2  stfips    zip  region  typebldg  no_stim  room stim  \\\n",
       "0   5081    MN     MN      27  55735       5         1        1     3    N   \n",
       "1   5082    MN     MN      27  55748       5         1        0     4    Y   \n",
       "2   5083    MN     MN      27  55748       5         1        0     4    Y   \n",
       "3   5084    MN     MN      27  56469       5         1        0     4    Y   \n",
       "4   5085    MN     MN      27  55011       3         1        0     4    Y   \n",
       "\n",
       "   ...  stopdt power  pcterr        adjwt  dupflag  zipflag  cntyfips  \\\n",
       "0  ...   12288   2.2     9.7  1146.499190        1        0         1   \n",
       "1  ...   12088   2.2    14.5   471.366223        0        0         1   \n",
       "2  ...   21188   2.9     9.6   433.316718        0        0         1   \n",
       "3  ...  123187   1.0    24.3   461.623670        0        0         1   \n",
       "4  ...   13088   3.1    13.8   433.316718        0        0         3   \n",
       "\n",
       "                  mouse   fips      Uppm  \n",
       "0  AITKIN                27001  0.502054  \n",
       "1  AITKIN                27001  0.502054  \n",
       "2  AITKIN                27001  0.502054  \n",
       "3  AITKIN                27001  0.502054  \n",
       "4  ANOKA                 27003  0.428565  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "srrs_mn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We also need a lookup table (`dict`) for each unique mouse, for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "srrs_mn.mouse = srrs_mn.mouse.map(str.strip)\n",
    "mn_mice = srrs_mn.mouse.unique()\n",
    "n_mice = len(mn_mice)\n",
    "mouse_lookup = dict(zip(mn_mice, range(n_mice)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Finally, create local copies of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "mouse = srrs_mn['mouse_code'] = srrs_mn.mouse.replace(mouse_lookup).values\n",
    "power = srrs_mn.power\n",
    "srrs_mn['log_power'] = log_power = np.log(power + 0.1).values\n",
    "no_stim = srrs_mn.no_stim.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Distribution of power levels (log scale):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "srrs_mn.log_power.hist(bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conventional approaches\n",
    "\n",
    "The two conventional alternatives to modeling power exposure represent the two extremes of the bias-variance tradeoff:\n",
    "\n",
    "***Complete pooling***: \n",
    "\n",
    "Treat all mice the same, and estimate a single power level.\n",
    "\n",
    "$$y_i = \\alpha + \\beta x_i + \\epsilon_i$$\n",
    "\n",
    "***No pooling***:\n",
    "\n",
    "Model power in each mouse independently.\n",
    "\n",
    "$$y_i = \\alpha_{j[i]} + \\beta x_i + \\epsilon_i$$\n",
    "\n",
    "where $j = 1,\\ldots,85$\n",
    "\n",
    "The errors $\\epsilon_i$ may represent measurement error, temporal within-neuron variation, or variation among neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complete pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll start by estimating the slope and intercept for the complete pooling model. You'll notice that we used an *index* variable instead of an *indicator* variable in the linear model below. There are two main reasons. One, this generalizes well to more-than-two-category cases. Two, this approach correctly considers that neither category has more prior uncertainty than the other. On the contrary, the indicator variable approach necessarily assumes that one of the categories has more uncertainty than the other: here, the cases when `no_stim=1` would take into account 2 priors ($\\alpha + \\beta$), whereas cases when `no_stim=0` would have only one prior ($\\alpha$). But *a priori* we aren't more unsure about no_stim measurements than about stim measurements, so it makes sense to give them the same prior uncertainty.\n",
    "\n",
    "Now for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"285pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 285.12 259.91\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 255.91)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-255.91 281.12,-255.91 281.12,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M20,-129.95C20,-129.95 110,-129.95 110,-129.95 116,-129.95 122,-135.95 122,-141.95 122,-141.95 122,-231.91 122,-231.91 122,-237.91 116,-243.91 110,-243.91 110,-243.91 20,-243.91 20,-243.91 14,-243.91 8,-237.91 8,-231.91 8,-231.91 8,-141.95 8,-141.95 8,-135.95 14,-129.95 20,-129.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-137.75\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster919</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M20,-8C20,-8 110,-8 110,-8 116,-8 122,-14 122,-20 122,-20 122,-109.95 122,-109.95 122,-115.95 116,-121.95 110,-121.95 110,-121.95 20,-121.95 20,-121.95 14,-121.95 8,-115.95 8,-109.95 8,-109.95 8,-20 8,-20 8,-14 14,-8 20,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"100\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">919</text>\n",
       "</g>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"65\" cy=\"-198.43\" rx=\"49.49\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-209.73\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-194.73\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-179.73\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"65\" cy=\"-76.48\" rx=\"49.49\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-87.78\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-72.78\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-57.78\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>a&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M65,-160.79C65,-149.38 65,-136.65 65,-124.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.5,-124.31 65,-114.31 61.5,-124.31 68.5,-124.31\"/>\n",
       "</g>\n",
       "<!-- sigma -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>sigma</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"205\" cy=\"-198.43\" rx=\"72.25\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"205\" y=\"-209.73\" font-family=\"Times,serif\" font-size=\"14.00\">sigma</text>\n",
       "<text text-anchor=\"middle\" x=\"205\" y=\"-194.73\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"205\" y=\"-179.73\" font-family=\"Times,serif\" font-size=\"14.00\">Exponential</text>\n",
       "</g>\n",
       "<!-- sigma&#45;&gt;y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>sigma&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168.22,-165.91C148.76,-149.25 124.85,-128.76 104.95,-111.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107.12,-108.96 97.25,-105.11 102.57,-114.27 107.12,-108.96\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc47abc4198>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with pm.Model() as pooled_model:\n",
    "    a = pm.Normal('a', 0., sigma=10., shape=2)\n",
    "    \n",
    "    theta = a[no_stim]\n",
    "    sigma = pm.Exponential('sigma', 1.)\n",
    "    \n",
    "    y = pm.Normal('y', theta, sigma=sigma, observed=log_power)\n",
    "    \n",
    "pm.model_to_graphviz(pooled_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Before running the model let's do some prior predictive checks. Indeed, having sensible priors is not only a way to incorporate scientific knowledge into the model, it can also help and make the MCMC machinery faster -- here we are dealing with a simple linear regression, so no link function comes and distorts the outcome space; but one day this will happen to you and you'll need to think hard about your priors to help your MCMC sampler. So, better to train ourselves when it's quite easy than having to learn when it's very hard... There is a really neat function to do that in PyMC3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with pooled_model:\n",
    "    prior_checks = pm.sample_prior_predictive(random_seed=RANDOM_SEED)\n",
    "\n",
    "plt.plot(\n",
    "    [0, 1], \n",
    "    [prior_checks[\"a\"][:, 0], prior_checks[\"a\"][:, 1]],\n",
    "    \"ok\",\n",
    "    alpha=0.2)\n",
    "plt.xlabel(\"no_stim measurement (binary)\")\n",
    "plt.xticks([0,1], [\"stim\", \"no_stim\"])\n",
    "plt.ylabel(\"Mean log power level\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "I'm no expert in power levels, but, before seing the data, these priors seem to allow for quite a wide range of the mean log power level. But don't worry, we can always change these priors if sampling gives us hints that they might not be appropriate -- after all, priors are assumptions, not oaths; and as most assumptions, they can be tested.\n",
    "\n",
    "However, we can already think of an improvement. Do you see it? Remember what we said at the beginning: power levels tend to be higher in stims, so we could incorporate this prior scientific knowledge into our model by giving $a_{stim}$ a higher mean than $a_{no_stim}$. Here, there are so much data that the prior should be washed out anyway, but we should keep this fact in mind -- for future cases or if sampling proves more difficult than expected...\n",
    "\n",
    "Speaking of sampling, let's fire up the Bayesian machinery!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10000' class='' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10000/10000 00:00<00:00 Average Loss = 1,150]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished [100%]: Average Loss = 1,149.9\n"
     ]
    }
   ],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with pooled_model:\n",
    "    pooled_trace = pm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    " \n",
    "# HIDE CODE\n",
    "\n",
    "with pooled_model:\n",
    "    start = pm.find_MAP()\n",
    "    pooled_trace = pm.sample(1000, pm.NUTS(scaling=start), start=start, random_seed=RANDOM_SEED)\n",
    "az.summary(pooled_trace, round_to=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with pooled_model:\n",
    "    pooled_trace = pm.sample(1000, tune=2000, random_seed=RANDOM_SEED)\n",
    "az.summary(pooled_trace, round_to=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "No divergences and a sampling that only took seconds -- this is the Flash of samplers! Here the chains look very good (good R hat, good effective sample size, small sd), but remember to check your chains after sampling -- `az.traceplot` is usually a good start.\n",
    "\n",
    "Let's see what it means on the outcome space: did the model pick-up the negative relationship between no_stim measurements and log power levels? What's the uncertainty around its estimates? To estimate the uncertainty around the neuron power levels (not the average level, but measurements that would be likely in neurons), we need to sample the likelihood `y` from the model. In another words, we need to do posterior predictive checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with pooled_model:\n",
    "    ppc = pm.sample_posterior_predictive(pooled_trace, random_seed=RANDOM_SEED)[\"y\"]\n",
    "\n",
    "a_stim, a_no_stim = pooled_trace[\"a\"].mean(axis=0)\n",
    "power_stim, power_no_stim = ppc[:, 1], ppc[:, 0] # we know that no_stim=0/1 at these columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can then use these samples in our plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_hpd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "plt.scatter(no_stim, log_power, label=\"Observations\", alpha=0.4)\n",
    "\n",
    "az.plot_hpd(\n",
    "    [0, 1], \n",
    "    np.asarray([power_stim, power_no_stim]).T, \n",
    "    fill_kwargs={\"alpha\": 0.2, \"label\": \"Exp. distrib. of power levels\"}\n",
    ")\n",
    "az.plot_hpd(\n",
    "    [0, 1], \n",
    "    pooled_trace[\"a\"], \n",
    "    fill_kwargs={\"alpha\": 0.5, \"label\": \"Exp. mean HPD\"}\n",
    ")\n",
    "plt.plot([0, 1], [a_stim, a_no_stim], label=\"Exp. mean\")\n",
    "\n",
    "plt.xticks([0,1], [\"stim\", \"no_stim\"])\n",
    "plt.xlabel(\"no_stim measurement (binary)\")\n",
    "plt.ylabel(\"Log power level\")\n",
    "plt.legend(ncol=2, fontsize=9, frameon=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The 94% interval of the expected value is very narrow, and even narrower for stim measurements, meaning that the model is slightly more confident about these observations. The sampling distribution of individual power levels is much wider. We can infer that no_stim level does account for some of the variation in power levels. We can see however that the model underestimates the dispersion in power levels across neurons -- lots of them lie outside the light orange prediction envelope. So this model is a good start but we can't stop there.\n",
    "\n",
    "Let's compare it to the unpooled model, where we estimate the power level for each mouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "n_mice,no_stim.shape,log_power.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "# updated version:\n",
    "with pm.Model() as unpooled_model:\n",
    "    a = pm.Normal('a', 0., sigma=10., shape=(n_mice, 2))\n",
    "    \n",
    "    theta = a[mouse, no_stim]\n",
    "    sigma = pm.Exponential('sigma', 1.)\n",
    "    \n",
    "    y = pm.Normal('y', theta, sigma=sigma, observed=log_power)\n",
    "\n",
    "pm.model_to_graphviz(unpooled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with unpooled_model:\n",
    "    unpooled_trace = pm.sample(1000, tune=2000, random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sampling went fine again. Let's look at the expected values for both stim (dimension 0) and no_stim (dimension 1) in each mouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "az.plot_forest(unpooled_trace, var_names=['a'], figsize=(6, 32), r_hat=True, combined=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sampling was good for all mice, but you can see that some are more uncertain than others, and all of these uncertain estimates are for no_stim measurements. This probably comes from the fact that some mice just have a handful of no_stim measurements, so the model is pretty uncertain about them.\n",
    "\n",
    "To identify mice with high power levels, we can plot the ordered mean estimates, as well as their 94% HPD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "a_stim_unpooled, a_no_stim_unpooled = unpooled_trace[\"a\"][:, :, 0], unpooled_trace[\"a\"][:, :, 1]\n",
    "unpooled_stim = pd.DataFrame.from_dict(\n",
    "                        {\n",
    "                            \"stim\": a_stim_unpooled.mean(0), \n",
    "                            \"low\": az.hpd(a_stim_unpooled)[:, 0], \n",
    "                            \"high\": az.hpd(a_stim_unpooled)[:, 1]\n",
    "                        }, \n",
    "                        orient=\"index\", \n",
    "                        columns=mn_mice\n",
    "                    ).T.sort_values(by=\"stim\")\n",
    "unpooled_no_stim = pd.DataFrame.from_dict(\n",
    "                    {\n",
    "                        \"no_stim\": a_no_stim_unpooled.mean(0),\n",
    "                        \"low\": az.hpd(a_no_stim_unpooled)[:, 0], \n",
    "                        \"high\": az.hpd(a_no_stim_unpooled)[:, 1]\n",
    "                    }, \n",
    "                    orient=\"index\", \n",
    "                    columns=mn_mice\n",
    "                ).T.sort_values(by=\"no_stim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "for ax, estimates, level in zip(axes, [unpooled_stim, unpooled_no_stim], [\"stim\", \"no_stim\"]):    \n",
    "    for i, l, h in zip(range(n_mice), estimates.low.values, estimates.high.values):\n",
    "        ax.plot([i, i], [l, h], alpha=0.6, c='orange')\n",
    "    ax.scatter(range(n_mice), estimates[level], alpha=0.8)\n",
    "    ax.set(title=f\"{level.title()} estimates\", xlabel=\"Ordered mouse\", xlim=(-1, 86), ylabel=\"power estimate\", ylim=(-2, 4.5))\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There seems to be more dispersion in power levels for no_stim measurements than for stim ones. Moreover, as we saw in the forest plot, no_stim estimates are globally more uncertain, especially in some mice. We speculated that this is due to smaller sample sizes in the data, but let's verify it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "n_no_stim_meas = srrs_mn.groupby(\"mouse\").sum().no_stim\n",
    "uncertainty = (unpooled_no_stim.high - unpooled_no_stim.low).sort_index() # sort index to match counties alphabetically\n",
    "\n",
    "plt.plot(n_no_stim_meas, uncertainty, 'o', alpha=.4)\n",
    "plt.xlabel(\"Nbr no_stim measurements in mouse\")\n",
    "plt.ylabel(\"Estimates' uncertainty\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bingo! This makes sense: it's very hard to estimate no_stim power levels in mice where there are no no_stim measurements, and the model is telling us that by being very uncertain in its estimates for those mice. This is a classic issue with no-pooling models: when you estimate clusters independently from each other, what do you with small-sample-size mice?\n",
    "\n",
    "Another way to see this phenomenon is to visually compare the pooled and unpooled estimates for a subset of mice representing a range of sample sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "# These mice were named as counties in Minnesota, how curious\n",
    "SAMPLE_mice = ('LAC QUI PARLE', 'AITKIN', 'KOOCHICHING', \n",
    "                    'DOUGLAS', 'CLAY', 'STEARNS', 'RAMSEY', 'ST LOUIS')\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6), sharey=True, sharex=True)\n",
    "axes = axes.ravel() \n",
    "for i, c in enumerate(SAMPLE_mice):\n",
    "    x = srrs_mn.no_stim[srrs_mn.mouse==c]\n",
    "    y = srrs_mn.log_power[srrs_mn.mouse==c]\n",
    "    \n",
    "    # plot obs:\n",
    "    axes[i].scatter(x + np.random.randn(len(x))*0.01, y, alpha=0.4)\n",
    "    \n",
    "    # plot both models:\n",
    "    axes[i].plot([0, 1], [unpooled_stim.loc[c, \"stim\"] , unpooled_no_stim.loc[c, \"no_stim\"]])\n",
    "    axes[i].plot([0, 1], [a_stim, a_no_stim], \"r--\")\n",
    "    \n",
    "    axes[i].set_xticks([0,1])\n",
    "    axes[i].set_xticklabels([\"stim\", \"no_stim\"])\n",
    "    axes[i].set_title(c)\n",
    "    if not i%2:\n",
    "        axes[i].set_ylabel(\"Log power level\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of these models are satisfactory:\n",
    "\n",
    "* If we are trying to identify high-power mice, pooling is useless -- because, by definition, the pooled model estimates power at the cohort-level. In other words, pooling leads to maximal *underfitting*: the variation across mice is not taken into account and only the overall population is estimated.\n",
    "* We do not trust extreme unpooled estimates produced by models using few observations. This leads to maximal *overfitting*: only the within-mouse variations are taken into account and the overall population (i.e the cohort-level, which tells us about similarites across mice) is not estimated. \n",
    "\n",
    "This issue is acute for small sample sizes, as seen above: in mice where we have few no_stim measurements, if power levels are higher for those data points than for stim ones (Aitkin, Koochiching, Ramsey), the model will estimate that power levels are higher in no_stims than stims for these mice. But we shouldn't trust this conclusion, because both scientific knowledge and the situation in other mice tell us that it is usually the reverse (stim power > no_stim power). So unless we have a lot of observations telling us otherwise for a given mouse, we should be skeptical and shrink our mouse-estimates to the cohort-estimates -- in other words, we should balance between cluster-level and population-level information, and the amount of shrinkage will depend on how extreme and how numerous the data in each cluster are. \n",
    "\n",
    "But how do we do that? Well, ladies and gentlemen, let me introduce you to... hierarchical models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilevel and hierarchical models\n",
    "\n",
    "When we pool our data, we imply that they are sampled from the same model. This ignores any variation among sampling units (other than sampling variance) -- we assume that mice are all the same:\n",
    "\n",
    "![pooled](http://f.cl.ly/items/0R1W063h1h0W2M2C0S3M/Screen%20Shot%202013-10-10%20at%208.22.21%20AM.png)\n",
    "\n",
    "When we analyze data unpooled, we imply that they are sampled independently from separate models. At the opposite extreme from the pooled case, this approach claims that differences between sampling units are too large to combine them -- we assume that mice have no similarity whatsoever:\n",
    "\n",
    "![unpooled](http://f.cl.ly/items/38020n2t2Y2b1p3t0B0e/Screen%20Shot%202013-10-10%20at%208.23.36%20AM.png)\n",
    "\n",
    "In a hierarchical model, parameters are viewed as a sample from a population distribution of parameters. Thus, we view them as being neither entirely different or exactly the same. This is ***partial pooling***:\n",
    "\n",
    "![hierarchical](http://f.cl.ly/items/1B3U223i002y3V2W3r0W/Screen%20Shot%202013-10-10%20at%208.25.05%20AM.png)\n",
    "\n",
    "We can use PyMC to easily specify multilevel models, and fit them using Markov chain Monte Carlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Partial pooling model\n",
    "\n",
    "The simplest partial pooling model for the neuron power dataset is one which simply estimates power levels, without any predictors at any level. A partial pooling model represents a compromise between the pooled and unpooled extremes, approximately a weighted average (based on sample size) of the unpooled mouse estimates and the pooled estimates.\n",
    "\n",
    "$$\\hat{\\alpha} \\approx \\frac{(n_j/\\sigma_y^2)\\bar{y}_j + (1/\\sigma_{\\alpha}^2)\\bar{y}}{(n_j/\\sigma_y^2) + (1/\\sigma_{\\alpha}^2)}$$\n",
    "\n",
    "Estimates for mice with smaller sample sizes will shrink towards the cohort-wide average.\n",
    "\n",
    "Estimates for mice with larger sample sizes will be closer to the unpooled mouse estimates and will influence the the cohort-wide average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with pm.Model() as partial_pooling:\n",
    "    # Hyperpriors:\n",
    "    a = pm.Normal('a', mu=0., sigma=10.)\n",
    "    sigma_a = pm.Exponential('sigma_a', 1.)\n",
    "    \n",
    "    # Varying intercepts:\n",
    "    a_mouse = pm.Normal('a_mouse', mu=a, sigma=sigma_a, shape=n_mice)\n",
    "    \n",
    "    # Expected value per mouse:\n",
    "    theta = a_mouse[mouse]\n",
    "    # Model error:\n",
    "    sigma = pm.Exponential('sigma', 1.)\n",
    "    \n",
    "    y = pm.Normal('y', theta, sigma=sigma, observed=log_power)\n",
    "pm.model_to_graphviz(partial_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with partial_pooling:\n",
    "    partial_pooling_trace = pm.sample(1000, tune=2000, random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To compare partial-pooling and no-pooling estimates, let's run the unpooled model without the `no_stim` predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with pm.Model() as unpooled_bis:\n",
    "    a_mouse = pm.Normal('a_mouse', 0., sigma=10., shape=n_mice)\n",
    "    \n",
    "    theta = a_mouse[mouse]\n",
    "    sigma = pm.Exponential('sigma', 1.)\n",
    "    \n",
    "    y = pm.Normal('y', theta, sigma=sigma, observed=log_power)\n",
    "    \n",
    "    unpooled_trace_bis = pm.sample(1000, tune=2000, random_seed=RANDOM_SEED)\n",
    "pm.model_to_graphviz(unpooled_bis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's compare both models' estimates for all 85 mice. We'll plot the estimates against each mouse's sample size, to let you see more clearly what hierarchical models bring to the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "N_mouse = srrs_mn.groupby(\"mouse\")[\"idnum\"].count().values\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True)\n",
    "for ax, trace, level in zip(\n",
    "    axes, \n",
    "    [unpooled_trace_bis[\"a_mouse\"], partial_pooling_trace[\"a_mouse\"]], \n",
    "    [\"no pooling\", \"partial pooling\"]\n",
    "):\n",
    "    ax.hlines(\n",
    "        partial_pooling_trace[\"a\"].mean(), \n",
    "        0.9, \n",
    "        max(N_mouse) + 1, \n",
    "        alpha=0.4, \n",
    "        ls=\"--\", \n",
    "        label=\"Est. population mean\"\n",
    "    )\n",
    "    for n, l, h in zip(\n",
    "        N_mouse, \n",
    "        az.hpd(trace)[:, 0], \n",
    "        az.hpd(trace)[:, 1]\n",
    "    ):\n",
    "        ax.plot([n, n], [l, h], alpha=0.5, c=\"orange\")\n",
    "    ax.scatter(N_mouse, trace.mean(0), alpha=0.8)\n",
    "    ax.set(\n",
    "        title=f\"{level.title()} Estimates\", \n",
    "        xlabel=\"Nbr obs in mouse (log scale)\", \n",
    "        xscale=\"log\", \n",
    "        ylabel=\"Log power\"\n",
    "    )\n",
    "    ax.legend(fontsize=10)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference between the unpooled and partially-pooled estimates, particularly at smaller sample sizes: As expected, the former are both more extreme and more imprecise. Indeed, in the partially-pooled model, estimates in small-sample-size mice are informed by the population parameters -- hence more precise estimates. Moreover, the smaller the sample size, the more regression towards the overall mean (the dashed gray line) -- hence less extreme estimates. In other words, the model is skeptical of extreme deviations from the population mean in mice where data is sparse. \n",
    "\n",
    "Now let's try to integrate the `no_stim` predictor! To show you an example with a slope we're gonna take the indicator variable road, but we could stay with the index variable approach that we used for the no-pooling model. Then we would have one intercept for each category -- stim and no_stim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Varying intercept model\n",
    "\n",
    "As above, this model allows intercepts to vary across mouse, according to a random effect. We just add a fixed slope for the predictor (i.e all mice will have the same slope):\n",
    "\n",
    "$$y_i = \\alpha_{j[i]} + \\beta x_{i} + \\epsilon_i$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\epsilon_i \\sim N(0, \\sigma_y^2)$$\n",
    "\n",
    "and the intercept random effect:\n",
    "\n",
    "$$\\alpha_{j[i]} \\sim N(\\mu_{\\alpha}, \\sigma_{\\alpha}^2)$$\n",
    "\n",
    "As with the the no-pooling model, we set a separate intercept for each mouse, but rather than fitting separate regression models for each mouse, multilevel modeling **shares strength** among mice, allowing for more reasonable inference in mice with little data. Here is what that looks in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with pm.Model() as varying_intercept:\n",
    "    # Hyperpriors:\n",
    "    a = pm.Normal('a', mu=0., sigma=10.)\n",
    "    sigma_a = pm.Exponential('sigma_a', 1.)\n",
    "    \n",
    "    # Varying intercepts:\n",
    "    a_mouse = pm.Normal('a_mouse', mu=a, sigma=sigma_a, shape=n_mice)\n",
    "    # Common slope:\n",
    "    b = pm.Normal('b', mu=0., sigma=10.)\n",
    "    \n",
    "    # Expected value per mouse:\n",
    "    theta = a_mouse[mouse] + b * no_stim\n",
    "    # Model error:\n",
    "    sigma = pm.Exponential('sigma', 1.)\n",
    "    \n",
    "    y = pm.Normal('y', theta, sigma=sigma, observed=log_power)\n",
    "pm.model_to_graphviz(varying_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's fit this bad boy with MCMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "with varying_intercept:\n",
    "    varying_intercept_trace = pm.sample(1000, tune=2000, random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "az.plot_forest(varying_intercept_trace, var_names=[\"a\", \"a_mouse\"], r_hat=True, combined=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "az.plot_trace(varying_intercept_trace, var_names=[\"sigma_a\", \"b\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "az.summary(varying_intercept_trace, var_names=[\"a\", \"sigma_a\", \"b\", \"sigma\"], round_to=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we suspected, the estimate for the `no_stim` coefficient is reliably negative and centered around -0.66. This can be interpreted as neurons without stims having about half ($\\exp(-0.66) = 0.52$) the power levels of those with stims, after accounting for mouse. Note that this is only the *relative* effect of no_stim on power levels: conditional on being in a given mouse, power is expected to be half lower in neurons without stims than in neurons with. To see how much difference a stim makes on the *absolute* level of power, we'd have to push the parameters through the model, as we do with posterior predictive checks and as we'll do just now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "xvals = np.arange(2)\n",
    "avg_a_mouse = varying_intercept_trace[\"a_mouse\"].mean(0)\n",
    "avg_b = varying_intercept_trace[\"b\"].mean()\n",
    "\n",
    "for a_c in avg_a_mouse:\n",
    "    plt.plot(xvals, a_c + avg_b * xvals, 'ko-', alpha=0.2)\n",
    "plt.xticks([0,1], [\"stim\", \"no_stim\"])\n",
    "plt.ylabel(\"Mean log power\")\n",
    "plt.title(\"MEAN LOG power BY mouse\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graph above shows, for each mouse, the expected log power level and the average effect of having no stim -- these are the absolute effects we were talking about. Two caveats though:\n",
    "1. This graph doesn't show the uncertainty for each mouse -- how confident are we that the average estimates are where the graph shows? For that we'd need to combine the uncertainty in `a_mouse` and `b`, and this would of course vary by mouse. I didn't show it here because the graph would get cluttered, but go ahead and do it for a subset of mice.\n",
    "2. These are only *average* estimates at the *mouse-level* (`theta` in the model): they don't take into account the variation by neuron. To add this other layer of uncertainty we'd need to take stock of the effect of `sigma` and generate samples from the `y` variable to see the effect on given neurons (that's exactly the role of posterior predictive checks).\n",
    "\n",
    "That being said, it is easy to show that the partial pooling model provides more objectively reasonable estimates than either the pooled or unpooled models, at least for mice with small sample sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 7), sharey=True, sharex=True)\n",
    "axes = axes.ravel()\n",
    "for i, c in enumerate(SAMPLE_mice):\n",
    "    x = srrs_mn.no_stim[srrs_mn.mouse==c]\n",
    "    y = srrs_mn.log_power[srrs_mn.mouse==c]\n",
    "    \n",
    "    # plot obs:\n",
    "    axes[i].scatter(x + np.random.randn(len(x))*0.01, y, alpha=0.4)\n",
    "    # complete-pooling model:\n",
    "    axes[i].plot([0, 1], [a_stim, a_no_stim], \"r--\", alpha=0.5, label=\"Complete pooling\")\n",
    "    # no-pooling model:\n",
    "    axes[i].plot(\n",
    "        [0, 1], \n",
    "        [unpooled_stim.loc[c, \"stim\"] , unpooled_no_stim.loc[c, \"no_stim\"]],\n",
    "        \"k:\",\n",
    "        alpha=0.5,\n",
    "        label=\"No pooling\"\n",
    "    )\n",
    "    # partial-pooling model:\n",
    "    axes[i].plot(\n",
    "        [0, 1], \n",
    "        [avg_a_mouse[mouse_lookup[c]], avg_a_mouse[mouse_lookup[c]] + avg_b],\n",
    "        label=\"Partial pooling\"\n",
    "    )\n",
    "    \n",
    "    axes[i].set_xticks([0,1])\n",
    "    axes[i].set_xticklabels([\"stim\", \"no_stim\"])\n",
    "    axes[i].set_title(c)\n",
    "    if not i%2:\n",
    "        axes[i].set_ylabel(\"Log power level\")\n",
    "    if not i%4:\n",
    "        axes[i].legend(fontsize=8, frameon=True)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we clearly see the notion that partial-pooling is a compromise between no pooling and complete pooling, as its mean estimates are usually between the other models' estimates. And interestingly, the bigger (smaller) the sample size in a given mouse, the closer the partial-pooling estimates are to the no-pooling (complete-pooling) estimates.\n",
    "\n",
    "We see however that mice vary by more than just their baseline rates: the effect of no_stim seems to be different from one mouse to another. It would be great if our model could take that into account, wouldn't it? Well to do that, we need to allow the slope to vary by mouse -- not only the intercept -- and here is how you can do it with PyMC3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Benefits of Multilevel Models\n",
    "\n",
    "- Accounting for natural hierarchical structure of observational data.\n",
    "\n",
    "- Estimation of coefficients for (under-represented) groups.\n",
    "\n",
    "- Incorporating individual- and group-level information when estimating group-level coefficients.\n",
    "\n",
    "- Allowing for variation among individual-level coefficients across groups.\n",
    "\n",
    "## References\n",
    "\n",
    "- Gelman, A., & Hill, J. (2006), *Data Analysis Using Regression and Multilevel/Hierarchical Models (1st ed.)*, Cambridge University Press.\n",
    "\n",
    "- Gelman, A. (2006), *Multilevel (Hierarchical) modeling: what it can and cannot do*, Technometrics, 48(3), 432–435.\n",
    "\n",
    "- McElreath, R. (2020), *Statistical Rethinking - A Bayesian Course with Examples in R and Stan (2nd ed.)*, CRC Press. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
